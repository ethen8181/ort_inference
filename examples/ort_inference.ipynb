{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#ORT-Inferencing\" data-toc-modified-id=\"ORT-Inferencing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>ORT Inferencing</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T14:35:49.497076Z",
     "start_time": "2021-06-14T14:35:49.145598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethen 2021-06-14 07:35:49 \n",
      "\n",
      "CPython 3.6.4\n",
      "IPython 7.15.0\n",
      "\n",
      "numpy 1.18.5\n",
      "onnxruntime 1.5.1\n"
     ]
    }
   ],
   "source": [
    "# 1. magic to print version\n",
    "# 2. magic so that the notebook will reload external python modules\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from onnxruntime import InferenceSession, SessionOptions\n",
    "\n",
    "%watermark -a 'Ethen' -d -t -v -p numpy,onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORT Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a [text (a.k.a. sequence) classification task](http://ethen8181.github.io/machine-learning/model_deployment/onnxruntime/text_classification_onnxruntime.html), performing inferencing using onnx runtime's python API often times looks like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T14:35:49.516229Z",
     "start_time": "2021-06-14T14:35:49.499227Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_inference_session(\n",
    "    model_path: str,\n",
    "    intra_op_num_threads: int = 4,\n",
    "    provider: str = 'CPUExecutionProvider'\n",
    ") -> InferenceSession: \n",
    "\n",
    "    # properties that might have an impact on performances (provided by MS)\n",
    "    options = SessionOptions()\n",
    "    options.intra_op_num_threads = intra_op_num_threads\n",
    "\n",
    "    # load the model as a onnx graph\n",
    "    session = InferenceSession(model_path, options, providers=[provider])\n",
    "    session.disable_fallback()\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T14:35:49.535291Z",
     "start_time": "2021-06-14T14:35:49.518126Z"
    }
   },
   "outputs": [],
   "source": [
    "intra_op_num_threads = 4\n",
    "\n",
    "onnx_model_path = \"text_classification.onnx\"\n",
    "\n",
    "input_id = [\n",
    "    101, 3183, 2079, 2017, 2293, 1996, 2087, 1998, 2339, 1029,\n",
    "    102, 3183, 2079, 2017, 2293, 2087, 1998, 2339, 1029, 102\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T14:35:50.343932Z",
     "start_time": "2021-06-14T14:35:49.561259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2110593,  1.7904084]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a session\n",
    "session = create_inference_session(onnx_model_path, intra_op_num_threads)\n",
    "\n",
    "# perform inferencing\n",
    "input_feed = {'input_ids': [input_id]}\n",
    "onnx_output = session.run(['output'], input_feed)[0]\n",
    "onnx_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works great for a single example, but when it comes to multiple examples each with different sequence length, directly passing these inputs to our `InferenceSession` will result in an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T14:35:50.377912Z",
     "start_time": "2021-06-14T14:35:50.349747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not create tensor from given input list\n"
     ]
    }
   ],
   "source": [
    "input_ids = [\n",
    "    [101, 3183, 2079, 2017, 2293, 1996, 2087, 1998, 2339, 1029,  102, 3183,\n",
    "     2079, 2017, 2293, 2087, 1998, 2339, 1029,  102],\n",
    "    [101, 2129, 2116, 9646, 2515, 1996, 5304, 2428, 2031, 1029,  102, 2129,\n",
    "     2116, 9646, 2024, 2045, 1029,  102]\n",
    "]\n",
    "try:\n",
    "    input_feed = {'input_ids': input_ids}\n",
    "    onnx_output = session.run(['output'], input_feed)[0]\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid this error message, we can either pad these inputs to the same sequence length or loop through them one by one to perform the graph execution. We perform the latter in the next code chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T14:35:50.407417Z",
     "start_time": "2021-06-14T14:35:50.382426Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_predict(session, input_ids):\n",
    "    batch_scores = []\n",
    "    for input_id in input_ids:\n",
    "        input_feed = {'input_ids': [input_id]}\n",
    "        onnx_output = session.run(['output'], input_feed)[0]\n",
    "        batch_scores.append(onnx_output)\n",
    "\n",
    "    return np.concatenate(batch_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T14:35:50.457811Z",
     "start_time": "2021-06-14T14:35:50.409668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2110593,  1.7904084],\n",
       "       [-1.1729933,  1.6591723]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_output = batch_predict(session, input_ids)\n",
    "onnx_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SequenceClassificationOrtInference` class allows us to directly feed our batches of dynamic sequence length to the `.batch_predict` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T14:35:51.194661Z",
     "start_time": "2021-06-14T14:35:50.460159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ort_inference.SequenceClassificationOrtInference at 0x7ff82cfb94c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ort_inference import SequenceClassificationOrtInference\n",
    "\n",
    "\n",
    "ort_inference = SequenceClassificationOrtInference(onnx_model_path, intra_op_num_threads)\n",
    "ort_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T14:35:51.248318Z",
     "start_time": "2021-06-14T14:35:51.197273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2110593,  1.7904084],\n",
       "       [-1.1729934,  1.6591723]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns a list of lists by default\n",
    "batch_score = ort_inference.batch_predict(input_ids)\n",
    "ort_output = np.array(batch_score, dtype=np.float32)\n",
    "ort_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm the output from both methods are identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T14:35:51.278272Z",
     "start_time": "2021-06-14T14:35:51.250594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(onnx_output, ort_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avoiding the for loop in Python also makes it faster when we are working with larger batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T14:35:51.303824Z",
     "start_time": "2021-06-14T14:35:51.280368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "input_ids = [input_id for _ in range(batch_size)]\n",
    "len(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T14:35:56.890387Z",
     "start_time": "2021-06-14T14:35:51.306909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689 ms ± 22 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "batch_predict(session, input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T14:36:01.086550Z",
     "start_time": "2021-06-14T14:35:56.892518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517 ms ± 10.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "batch_score = ort_inference.batch_predict(input_ids)\n",
    "ort_output = np.array(batch_score, dtype=np.float32)\n",
    "ort_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "248.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
